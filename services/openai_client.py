import requests
import json
import os
from dotenv import load_dotenv
from utils.decorators import safe_exec, log_execution, timed
from utils.dependency_injector import inject_dependencies
from utils.logger import Logger
from utils.config import Config

load_dotenv()

@timed
@log_execution
@safe_exec
@inject_dependencies
def call_openai_llm(
    prompt: str, 
    api_url: str = None, 
    api_key: str = None, 
    model: str = None,
    logger: Logger = None,
    config: Config = None
) -> dict:
    """
    Appelle l'API OpenAI (ou compatible) pour obtenir un r√©sum√©.
    Ne stocke pas la cl√©, ne log rien de sensible.
    
    Args:
        prompt: Le texte √† soumettre √† OpenAI
        api_url: URL de l'API OpenAI (d√©faut: valeur d'environnement)
        api_key: Cl√© API OpenAI (d√©faut: valeur d'environnement)
        model: Le mod√®le √† utiliser (d√©faut: d√©fini dans config)
        logger: Instance de logger inject√©e
        config: Instance de configuration inject√©e
        
    Returns:
        dict: La r√©ponse d'OpenAI avec le r√©sum√© et les infos sur les tokens
    """
    api_url = api_url or os.getenv("OPENAI_API_URL") or config.OPENAI_API_URL
    api_key = api_key or os.getenv("OPENAI_API_KEY")
    model = model or config.OPENAI_MODEL

    # Masquer la cl√© API dans les logs
    masked_key = "***" if api_key else "non fournie"
    logger.debug(f"ü§ñ Appel OpenAI avec mod√®le: {model}, API Key: {masked_key}")

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": "Tu es un assistant qui r√©sume du contenu."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.5
    }

    try:
        logger.debug(f"üõ†Ô∏è Payload size: {len(str(data))} chars")
        logger.debug(f"üõ†Ô∏è Prompt preview: {data['messages'][-1]['content'][:50]}")
        logger.debug(f"üõ†Ô∏è Utilisation du mod√®le: {model}")
        response = requests.post(api_url, headers=headers, json=data)
        response.raise_for_status()
        json_response = response.json()

        # Calculer les statistiques de tokens pour les logs
        total_tokens = json_response.get("usage", {}).get("total_tokens", 0) 
        prompt_tokens = json_response.get("usage", {}).get("prompt_tokens", 0)
        completion_tokens = json_response.get("usage", {}).get("completion_tokens", 0)
        
        logger.debug(f"üì• R√©ponse OpenAI re√ßue: {total_tokens} tokens au total " +
                    f"({prompt_tokens} prompt, {completion_tokens} r√©ponse)")

        return {
            "response": json_response["choices"][0]["message"]["content"],
            "tokens_used": json_response.get("usage", {})
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'appel √† OpenAI: {str(e)}")
        return {
            "response": f"Erreur appel OpenAI : {str(e)}",
            "tokens_used": {}
        }
