import requests
import json
from utils.decorators import safe_exec, log_execution, timed
from utils.dependency_injector import inject_dependencies
from utils.logger import Logger
from utils.config import Config

@timed
@log_execution
@safe_exec
@inject_dependencies
def call_ollama_llm(
    prompt: str, 
    model: str = "llama3", 
    stream: bool = False,
    logger: Logger = None,
    config: Config = None
) -> dict:
    """
    Envoie une requ√™te √† Ollama pour g√©n√©rer un r√©sum√©.
    
    Args:
        prompt: Le texte √† soumettre √† Ollama
        model: Le mod√®le √† utiliser (d√©faut: d√©fini dans config)
        stream: Si True, utilise le streaming pour la r√©ponse
        logger: Instance de logger inject√©e
        config: Instance de configuration inject√©e
        
    Returns:
        dict: La r√©ponse d'Ollama avec le r√©sum√© et les infos sur les tokens
    """
    # Utiliser le mod√®le par d√©faut de la config si non sp√©cifi√©
    model = model or "llama3"
    
    url = "http://localhost:11434/api/generate"
    logger.debug(f"ü¶ô Appel Ollama avec mod√®le: {model}")

    data = {
        "model": model,
        "prompt": prompt,
        "stream": stream
    }

    headers = {"Content-Type": "application/json"}

    try:
        logger.debug(f"üì§ Envoi de la requ√™te Ollama (longueur prompt: {len(prompt)} caract√®res)")
        response = requests.post(url, data=json.dumps(data), headers=headers, stream=stream)
        response.raise_for_status()

        if stream:
            full_response = ""
            for line in response.iter_lines():
                if line:
                    decoded_line = json.loads(line.decode("utf-8"))
                    full_response += decoded_line.get("response", "")
            result = full_response
        else:
            result = response.json().get("response", "")
            
        logger.debug(f"üì• R√©ponse Ollama re√ßue (longueur: {len(result)} caract√®res)")
        return {
            "response": result,
            "tokens_used": {}  # Ollama ne fournit pas les tokens
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'appel √† Ollama: {str(e)}")
        return {
            "response": f"Erreur lors de l'appel √† Ollama : {str(e)}",
            "tokens_used": {}
        }
