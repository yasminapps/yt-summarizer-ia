# ğŸ§  Project Architecture - yt-summarizer-ia

## ğŸ“ Project Structure

yt-summarizer-ia/
â”‚
â”œâ”€â”€ app.py                       # Entry point of the Flask application
â”œâ”€â”€ config.py                    # Optional config file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ CONTRIBUTING.md              # Contribution guidelines
â”œâ”€â”€ README.md                    # Project overview and usage
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html               # Main HTML interface
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css                # CSS styles
â”‚   â””â”€â”€ script.js                # Frontend interactivity (toggle, auto-language)
â”‚
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ summarize.py             # POST route to handle summarization
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ openai_client.py         # Calls OpenAI API (remote summarization)
â”‚   â”œâ”€â”€ ollama_client.py         # Calls local Ollama server (offline summarization)
â”‚   â”œâ”€â”€ youtube_transcript.py    # Extracts YouTube transcript from video URL
â”‚   â””â”€â”€ ia_client_factory.py     # Chooses LLM engine (OpenAI vs Ollama)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ formatter.py             # Cleans up transcript text
â”‚   â”œâ”€â”€ logger.py                # (Optional) logging utility
â”‚   â””â”€â”€ decorators.py            # (Optional) decorators
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py              # Unit test for API behavior
â”‚
â””â”€â”€ docs/
â””â”€â”€ architecture.md          # Current documentation file


---

## ğŸ§© Core Components

| Component              | Description                                                            |
|------------------------|------------------------------------------------------------------------|
| `Flask`                | Lightweight web server for routing and request handling                |
| `YouTubeTranscriptAPI` | Extracts video subtitles automatically                                 |
| `Ollama`               | Local LLM engine (e.g. LLaMA3) without Internet access                 |
| `OpenAI API`           | Remote LLM engine (GPT-3.5/4), requires API key and endpoint           |
| `dotenv`               | Loads environment variables from `.env` securely                      |
| `HTML/CSS/JS`          | User interface with multi-language and interactive elements            |

---

## ğŸ” Execution Workflow

1. User submits a YouTube URL, chooses the LLM engine, summary type, target language, and detail level.
2. The backend fetches the video transcript.
3. A tailored prompt is generated based on user inputs.
4. The IA engine is selected via the `ia_client_factory`.
5. The summary is generated using OpenAI or Ollama.
6. The result (summary + optional token usage) is returned to the frontend.

---

## ğŸ§± Design Patterns & Best Practices

- **Factory Pattern**: `get_llm_client()` dynamically selects the correct LLM engine.
- **Separation of Concerns**: Clear separation between logic (`services`), interface (`routes`, `templates`), and utilities (`utils`).
- **Environment Safety**: `.env` file is used via `python-dotenv` to protect sensitive credentials.
- **Frontend Modularity**: JavaScript and CSS are in separate files for maintainability.
- **Multilingual UX**: Auto-detects browser language and allows any language via `datalist`.
- **Open Source Ready**: Standard GitHub layout, documentation folder, clear modular structure.

---

## ğŸ“Œ Notes

- The project is designed for easy contribution, modular evolution, and eventual deployment.
- Future enhancements include automatic language detection, caching, user auth, and UI refinement.
